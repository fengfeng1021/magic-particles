// src/components/Webcam/HandTracker.jsx
import { useEffect, useRef, useState } from 'react'
import { FilesetResolver, HandLandmarker } from '@mediapipe/tasks-vision'

export default function HandTracker({ onHandUpdate }) {
  const videoRef = useRef(null)
  const handLandmarkerRef = useRef(null)
  const animationFrameId = useRef(null)
  
  const [isStarted, setIsStarted] = useState(false)
  const [statusMsg, setStatusMsg] = useState('')

  const startCamera = async () => {
    setIsStarted(true)
    
    try {
      // --- éšæ®µ 1: æ¸¬è©¦ç€è¦½å™¨æ”¯æ´åº¦ ---
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error("æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æ´æ”åƒé ­ API (navigator.mediaDevices is missing)")
      }

      // --- éšæ®µ 2: è¼‰å…¥ AI æ¨¡å‹ ---
      setStatusMsg('æ­¥é©Ÿ 1/3: ä¸‹è¼‰ AI æ¨¡å‹...')
      console.log('æ­£åœ¨è¼‰å…¥ WASM:', import.meta.env.BASE_URL + 'models/vision_wasm_internal.wasm')
      
      const vision = await FilesetResolver.forVisionTasks(
        import.meta.env.BASE_URL + 'models/vision_wasm_internal.wasm'
      )

      handLandmarkerRef.current = await HandLandmarker.createFromOptions(
        vision,
        {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
            delegate: 'CPU', // iOS å¿…é ˆç”¨ CPU
          },
          runningMode: 'VIDEO',
          numHands: 1,
        }
      )

      // --- éšæ®µ 3: å•Ÿå‹•æ”åƒé ­ (æœ€ç°¡åŒ–é…ç½®) ---
      setStatusMsg('æ­¥é©Ÿ 2/3: ç­‰å¾…æ”åƒé ­æˆæ¬Š...')
      
      // âš ï¸ ä¿®æ­£ï¼šiOS æœ‰æ™‚å€™å° width/height é™åˆ¶å¾ˆæ•æ„Ÿï¼Œæˆ‘å€‘å…ˆç”¨æœ€åŸºæœ¬çš„ { video: true } ç¢ºä¿èƒ½è·‘
      // ä½¿ç”¨ facingMode: 'user' æŒ‡å®šå‰é¡é ­
      const constraints = { 
        video: { facingMode: 'user' }, 
        audio: false 
      }

      const stream = await navigator.mediaDevices.getUserMedia(constraints)
      
      setStatusMsg('æ­¥é©Ÿ 3/3: å•Ÿå‹•å½±åƒä¸²æµ...')

      if (videoRef.current) {
        videoRef.current.srcObject = stream
        // iOS å¿…é ˆé¡¯å¼èª¿ç”¨ play
        await videoRef.current.play()
        
        videoRef.current.onloadeddata = () => {
          setStatusMsg('') // æˆåŠŸï¼æ¸…é™¤è¨Šæ¯
          predictWebcam()
        }
      }

    } catch (error) {
      console.error("è©³ç´°éŒ¯èª¤:", error)
      
      // ğŸ•µï¸â€â™‚ï¸ éŒ¯èª¤åµæ¢ï¼šå˜—è©¦è§£æå„ç¨®å¥‡æ€ªçš„éŒ¯èª¤æ ¼å¼
      let errorText = "æœªçŸ¥éŒ¯èª¤"
      if (typeof error === 'string') {
        errorText = error
      } else if (error instanceof Error) {
        errorText = `${error.name}: ${error.message}`
      } else {
        // å˜—è©¦è½‰æˆ JSONï¼Œå¦‚æœä¸è¡Œå°±è½‰å­—ä¸²
        try {
          errorText = JSON.stringify(error)
        } catch (e) {
          errorText = String(error)
        }
      }
      
      // å¦‚æœæ˜¯ç‰¹å®šçš„å¸¸è¦‹éŒ¯èª¤ï¼Œçµ¦äºˆç™½è©±æ–‡æç¤º
      if (errorText.includes("NotAllowedError") || errorText.includes("Permission denied")) {
        errorText = "æ¬Šé™è¢«æ‹’çµ•ã€‚è«‹åˆ° iOS è¨­å®š > Safari > ç›¸æ©Ÿï¼Œæ”¹ç‚ºã€Œå…è¨±ã€ã€‚"
      }
      
      setStatusMsg(`âŒ å¤±æ•—: ${errorText}`)
      setIsStarted(false) // å…è¨±é‡è©¦
    }
  }

  // ... (predictWebcam å’Œ useEffect ä¿æŒä¸è®Šï¼Œç…§èˆŠ) ...
  const predictWebcam = () => {
    if (handLandmarkerRef.current && videoRef.current && videoRef.current.readyState === 4) {
      const results = handLandmarkerRef.current.detectForVideo(videoRef.current, Date.now())

      if (results.landmarks && results.landmarks.length > 0) {
        const hand = results.landmarks[0]
        const indexTip = hand[8]
        const thumbTip = hand[4]
        
        const x = (0.5 - indexTip.x) * 2 
        const y = -(indexTip.y - 0.5) * 2

        const distance = Math.sqrt(
          Math.pow(indexTip.x - thumbTip.x, 2) + 
          Math.pow(indexTip.y - thumbTip.y, 2)
        )
        const isPinching = distance < 0.1

        onHandUpdate({ x, y, isPinching })
      } else {
        onHandUpdate(null)
      }
    }
    animationFrameId.current = requestAnimationFrame(predictWebcam)
  }

  useEffect(() => {
    return () => {
      if (animationFrameId.current) cancelAnimationFrame(animationFrameId.current)
      if (handLandmarkerRef.current) handLandmarkerRef.current.close()
    }
  }, [])

  return (
    <>
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        style={{ width: '1px', height: '1px', opacity: 0, position: 'absolute' }}
      />

      {!isStarted && (
        <div style={{
          position: 'absolute', top: 0, left: 0, width: '100%', height: '100%',
          display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center',
          backgroundColor: 'rgba(0,0,0,0.8)', zIndex: 9999, padding: '20px', textAlign: 'center'
        }}>
          <button 
            onClick={startCamera}
            style={{
              padding: '15px 30px', fontSize: '20px', cursor: 'pointer',
              background: '#00ffff', border: 'none', borderRadius: '50px',
              boxShadow: '0 0 20px #00ffff', color: '#000', fontWeight: 'bold', marginBottom: '20px'
            }}
          >
            {statusMsg && statusMsg.includes("âŒ") ? "å†è©¦ä¸€æ¬¡" : "âœ¨ å•Ÿå‹•é­”æ³•"}
          </button>
          
          {/* é¡¯ç¤ºç´…è‰²çš„éŒ¯èª¤è¨Šæ¯ */}
          {statusMsg && statusMsg.includes("âŒ") && (
            <div style={{color: '#ff5555', background: 'rgba(50,0,0,0.8)', padding: '10px', borderRadius: '5px'}}>
              {statusMsg}
            </div>
          )}
        </div>
      )}

      {/* é¡¯ç¤ºè¼‰å…¥ä¸­çš„è—è‰²è¨Šæ¯ */}
      {isStarted && statusMsg && !statusMsg.includes("âŒ") && (
        <div style={{
          position: 'absolute', top: '50%', left: '50%', transform: 'translate(-50%, -50%)',
          color: '#00ffff', fontSize: '18px', zIndex: 9998, background: 'rgba(0,0,0,0.5)', padding: '10px', borderRadius: '10px'
        }}>
          {statusMsg}
        </div>
      )}
    </>
  )
}